---
title: Limit
description: Limit the number of rows
---

<Panel>
<Info>
Dependencies:

- ProphecySparkBasicsPython 0.0.1+
- ProphecySparkBasicsScala 0.0.1+

</Info>

<Info>

Cluster requirements:

- UC dedicated clusters 14.3+ supported
- UC standard clusters 14.3+ supported
- Livy clusters 3.0.1+ supported

</Info>
</Panel>

Limits the number of rows in the output.

## Parameters

| Parameter | Description |
| :-------- | :----------------------------------------------------------------------- |
| DataFrame | Input DataFrame |
| Limit | Number of rows required in output. Allowed range: [0, 2<sup>31</sup> -1] |

## Limit to 10 rows

If you want to limit your output to 10 rows, you can input `10` in the Limit gem.

![Example usage of Limit](./img/limit_eg_1.png)

<Note>
[Data samples](/engineers/execution) generated before the Limit gem might also be limited. This is because Spark tries to push the limit down to earlier stages of execution to minimize data processing. This means Spark may reduce the number of rows fetched from the source or processed in earlier transformations.
</Note>

## Code

<CodeGroup>

```python example.py
def limit(spark: SparkSession, in0: DataFrame) -> DataFrame:
 return in0.limit(10)
```

```scala example.scala
object limit {
 def apply(spark: SparkSession, in: DataFrame): DataFrame =
 in.limit(10)
}
```

</CodeGroup>
